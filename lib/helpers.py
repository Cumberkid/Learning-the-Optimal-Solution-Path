# -*- coding: utf-8 -*-
"""helpers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14tdaulQMMrW53XVmxCkNtwUwvRZ23W0E
    
# Helper functions to test convergence
"""
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader  #for creating the dataset

#Prep data for Pytorch Dataloader
class Regression_Data(Dataset):
    def __init__(self, X, y):
        self.X = X  if isinstance(X, torch.Tensor) else torch.FloatTensor(X)
        self.y = y  if isinstance(y, torch.Tensor) else torch.FloatTensor(y)
        self.input_dim = self.X.shape[1]

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        return self.X[idx,:], self.y[idx]

    def get_y(self):
        return self.y

#A silly synthetic data example
def gen_data(n_obs_1, n_obs_2, n_var):
    # Draw X randomly
    data_1 = np.random.multivariate_normal(
             np.zeros(n_var),
             np.eye(n_var),
             n_obs_1
             )

    data_2 = np.random.multivariate_normal(
             np.ones(n_var),
             np.eye(n_var),
             n_obs_2
             )

    data = np.vstack((data_1, data_2))

    # Create corresponding labels (0 for the first distribution, 1 for the second)
    labels = np.hstack((np.zeros(n_obs_1), np.ones(n_obs_2)))

    # Shuffle the data and labels
    shuffled_indices = np.random.permutation(data.shape[0])
    data = data[shuffled_indices]
    labels = labels[shuffled_indices]
    return data.astype(np.float32), labels.astype(np.float32)
    

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def gradient_descent(X, y, weights, lam, learning_rate, num_iterations):
    m = len(y)
    for i in range(num_iterations):
        y_pred = sigmoid(np.dot(X, weights))
        gradient = (1-lam) * np.dot(X.T, y_pred - y) / m + lam * weights
        weights -= learning_rate * gradient
    return weights

def logit_by_hand(weight, intercept, lam, X_set, y_set):
    # weight = torch.zeros(input_dim, 1)
    pred = torch.sigmoid(torch.mm(X_set, weight) + intercept)
    # print(pred)
    criterion = torch.nn.BCELoss()
    soln = (1 - lam) * criterion(torch.squeeze(pred), y_set)
    soln += lam * 0.5 * (torch.squeeze(weight).norm(p=2)**2 + torch.squeeze(intercept)**2)

    return soln, pred
